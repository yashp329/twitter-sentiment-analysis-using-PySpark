{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dddc90bc-36f1-489e-b714-e5188517f7d4",
     "showTitle": false,
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "POJenyRlt0Xz",
    "outputId": "cb1f307d-9b6b-4911-b756-b1af38a43bff"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[43mNote: you may need to restart the kernel using dbutils.library.restartPython() to use updated packages.\u001B[0m\nCollecting pyspark\n  Downloading pyspark-3.5.1.tar.gz (317.0 MB)\n     ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 317.0/317.0 MB 2.2 MB/s eta 0:00:00\n  Preparing metadata (setup.py): started\n  Preparing metadata (setup.py): finished with status 'done'\nCollecting py4j==0.10.9.7\n  Downloading py4j-0.10.9.7-py2.py3-none-any.whl (200 kB)\n     ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 200.5/200.5 kB 26.4 MB/s eta 0:00:00\nBuilding wheels for collected packages: pyspark\n  Building wheel for pyspark (setup.py): started\n  Building wheel for pyspark (setup.py): finished with status 'done'\n  Created wheel for pyspark: filename=pyspark-3.5.1-py2.py3-none-any.whl size=317488496 sha256=e675eeb8cc9d2106d27c89ef9cc995d73f108b81afa5828891b91c605a62204b\n  Stored in directory: /home/spark-298e7b4d-0412-46c2-9d59-f2/.cache/pip/wheels/22/f3/c0/49d7c304ee9ebfd58d8417a140fa93a306ea3d28d19e9af018\nSuccessfully built pyspark\nInstalling collected packages: py4j, pyspark\nSuccessfully installed py4j-0.10.9.7 pyspark-3.5.1\n\u001B[43mNote: you may need to restart the kernel using dbutils.library.restartPython() to use updated packages.\u001B[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install pyspark\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName(\"Data Preprocessing\").getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2b6426cb-a941-45a6-8a59-26bb0d80d30b",
     "showTitle": false,
     "title": ""
    },
    "id": "-jRQq1yUORnw"
   },
   "source": [
    "### READING THE DATASETS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "13ac3593-6786-4aeb-ba3a-74ea5d9ffa14",
     "showTitle": false,
     "title": ""
    },
    "id": "V7JK74-Xrqtb"
   },
   "outputs": [],
   "source": [
    "trump_df = spark.read.format(\"csv\").option(\"header\", \"true\").option(\"inferSchema\",\"true\").option(\"quote\", \"\\\"\").option(\"escape\", \"\\\"\").option(\"multiline\", True).load(\"/mnt/2024-team19/hashtag_donaldtrump.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b98406eb-af7d-4b35-9b64-a8ec8c752027",
     "showTitle": false,
     "title": ""
    },
    "id": "MHDEHUCdrqtc"
   },
   "outputs": [],
   "source": [
    "biden_df = spark.read.format(\"csv\").option(\"header\", \"true\").option(\"inferSchema\",\"true\").option(\"quote\", \"\\\"\").option(\"escape\", \"\\\"\").option(\"multiline\", True).load(\"/mnt/2024-team19/hashtag_joebiden.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6502adf5-590c-40c5-93b5-2ddded9a333c",
     "showTitle": false,
     "title": ""
    },
    "id": "LUfH8yirO3FN"
   },
   "source": [
    "### DATA PREPROCESSING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "38e199dc-3aae-4422-b7a9-b2aa6e40e97a",
     "showTitle": false,
     "title": ""
    },
    "id": "guun8RZCQxPd"
   },
   "source": [
    "### 1. CREATING A NEW COLUMN HASHTAG FOR JOE BIDEN AND DONALD TRUMP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0ab16850-f766-4b22-818d-fbd476cd1087",
     "showTitle": false,
     "title": ""
    },
    "id": "koPi8SauQsh4"
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import lit\n",
    "# Creating a new column named 'hashtag' with the value 'Trump'\n",
    "trump_df = trump_df.withColumn(\"hashtag\", lit(\"Trump\"))\n",
    "\n",
    "# Creating a new column named 'hashtag' with the value 'Biden'\n",
    "biden_df = biden_df.withColumn(\"hashtag\", lit(\"Biden\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "227bfcbe-20bf-4ca7-82c5-3fae75214c65",
     "showTitle": false,
     "title": ""
    },
    "id": "p7LcngMhQ2eu"
   },
   "source": [
    "### 2. MERGING BOTH THE DATAFRAMES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "185f1ea8-ad27-45c7-bee8-b29ac05209c7",
     "showTitle": false,
     "title": ""
    },
    "id": "PYmDUW9GQ2Sx"
   },
   "outputs": [],
   "source": [
    "combined_df = trump_df.union(biden_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0a27d8c8-726c-4026-94e4-b28abdee6262",
     "showTitle": false,
     "title": ""
    },
    "id": "DQSG09-aQHdl"
   },
   "source": [
    "### 3. FILTERING THE DATA FOR UNITED STATES OF AMERICA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f14ef6db-8448-4b3d-ab15-b5367b673cc5",
     "showTitle": false,
     "title": ""
    },
    "id": "LyTfR4eoQH9I"
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col\n",
    "filtered_df = combined_df.filter((col(\"Country\") == \"United States of America\") | (col(\"Country\") == \"United States\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "781fae2c-d16c-4e0f-8ed3-649fee26dd1d",
     "showTitle": false,
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4TB0LWGtrqtc",
    "outputId": "668189e5-682a-4323-f386-b8291b34602b"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+--------------------+--------------------+-----+-------------+-------------------+--------------------+--------------------+----------------+--------------------+-------------------+--------------------+--------------------+------------------+-------------------+----------+--------------------+-------------+--------------------+----------+--------------------+-------+\n|         created_at|            tweet_id|               tweet|likes|retweet_count|             source|             user_id|           user_name|user_screen_name|    user_description|     user_join_date|user_followers_count|       user_location|               lat|               long|      city|             country|    continent|               state|state_code|        collected_at|hashtag|\n+-------------------+--------------------+--------------------+-----+-------------+-------------------+--------------------+--------------------+----------------+--------------------+-------------------+--------------------+--------------------+------------------+-------------------+----------+--------------------+-------------+--------------------+----------+--------------------+-------+\n|2020-10-15 00:00:01|1.316529221557252...|#Elecciones2020 |...|  0.0|          0.0|          TweetDeck|        3.60666534E8|  El Sol Latino News| elsollatinonews|üåê Noticias de in...|2011-08-23 15:33:45|              1860.0|Philadelphia, PA ...|          25.77427|          -80.19366|      NULL|United States of ...|North America|             Florida|        FL| 2020-10-21 00:00:00|  Trump|\n|2020-10-15 00:00:02|1.316529228091846...|#Trump: As a stud...|  2.0|          1.0|    Twitter Web App|           8436472.0|              snarke|          snarke|Will mock for foo...|2007-08-26 05:56:11|              1185.0|            Portland|        45.5202471|       -122.6741949|  Portland|United States of ...|North America|              Oregon|        OR|2020-10-21 00:00:...|  Trump|\n|2020-10-15 00:00:08|1.316529252301451...|You get a tie! An...|  4.0|          3.0| Twitter for iPhone|         4.7413798E7|Rana Abtar - ÿ±ŸÜÿß ...|       Ranaabtar|Washington Corres...|2009-06-15 19:05:35|              5393.0|       Washington DC|        38.8949924|        -77.0365581|Washington|United States of ...|North America|District of Columbia|        DC|2020-10-21 00:00:...|  Trump|\n|2020-10-15 00:00:17|1.316529291052675...|@CLady62 Her 15 m...|  2.0|          0.0|Twitter for Android|       1.138416104E9|        Farris Flagg|     FarrisFlagg|#BidenHarris2020 ...|2013-02-01 01:37:38|              2363.0|   Perris,California|        33.7825194|-117.22864779999999|      NULL|United States of ...|North America|          California|        CA|2020-10-21 00:00:...|  Trump|\n|2020-10-15 00:00:18|1.316529293497962...|@DeeviousDenise @...|  0.0|          0.0| Twitter for iPhone|9.007610716314296...|Stacey Gulledge ?...|     sm_gulledge|Patriot, Wife, ‚ÄúS...|2017-08-24 16:45:49|               766.0|           Ohio, USA|40.225356899999994|        -82.6881395|      NULL|United States of ...|North America|                Ohio|        OH|2020-10-21 00:00:...|  Trump|\n+-------------------+--------------------+--------------------+-----+-------------+-------------------+--------------------+--------------------+----------------+--------------------+-------------------+--------------------+--------------------+------------------+-------------------+----------+--------------------+-------------+--------------------+----------+--------------------+-------+\nonly showing top 5 rows\n\n"
     ]
    }
   ],
   "source": [
    "filtered_df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "59bc9eb5-49fe-4c1f-a8e6-4fd3d09fb7b6",
     "showTitle": false,
     "title": ""
    },
    "id": "tjXP-121T_ZA"
   },
   "source": [
    "### 4. DROPPING UNNECESSARY COLUMNS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5da3011a-eb4e-419c-86b8-ab08997c6937",
     "showTitle": false,
     "title": ""
    },
    "id": "wVv3YMy4T_CI"
   },
   "outputs": [],
   "source": [
    "columns_to_drop =['created_at',\n",
    " 'tweet_id',\n",
    " 'retweet_count',\n",
    " 'likes',\n",
    " 'source',\n",
    " 'user_id',\n",
    " 'user_name',\n",
    " 'user_screen_name',\n",
    " 'user_description',\n",
    " 'user_join_date',\n",
    " 'user_followers_count',\n",
    " 'user_location',\n",
    " 'lat',\n",
    " 'long',\n",
    " 'city',\n",
    " 'country',\n",
    " 'continent',\n",
    " 'state',\n",
    " 'state_code',\n",
    " 'collected_at',\n",
    " 'sentiment_score',\n",
    " 'sentiment_label',\n",
    " ]\n",
    "\n",
    "# Drop the specified columns\n",
    "filtered_df = filtered_df.drop(*columns_to_drop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6b47b2a1-0c45-48cd-8e45-ae63c8bd29b8",
     "showTitle": false,
     "title": ""
    },
    "id": "GmzlDJ2_O7IO"
   },
   "source": [
    "#### 5. CREATING A SENTIMENT COLUMN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f0b217c1-cef5-4301-8cc3-bd64870fce16",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[43mNote: you may need to restart the kernel using dbutils.library.restartPython() to use updated packages.\u001B[0m\nCollecting vaderSentiment\n  Downloading vaderSentiment-3.3.2-py2.py3-none-any.whl (125 kB)\n     ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 126.0/126.0 kB 3.5 MB/s eta 0:00:00\nRequirement already satisfied: requests in /databricks/python3/lib/python3.10/site-packages (from vaderSentiment) (2.28.1)\nRequirement already satisfied: idna<4,>=2.5 in /databricks/python3/lib/python3.10/site-packages (from requests->vaderSentiment) (3.4)\nRequirement already satisfied: charset-normalizer<3,>=2 in /databricks/python3/lib/python3.10/site-packages (from requests->vaderSentiment) (2.0.4)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /databricks/python3/lib/python3.10/site-packages (from requests->vaderSentiment) (1.26.14)\nRequirement already satisfied: certifi>=2017.4.17 in /databricks/python3/lib/python3.10/site-packages (from requests->vaderSentiment) (2022.12.7)\nInstalling collected packages: vaderSentiment\nSuccessfully installed vaderSentiment-3.3.2\n\u001B[43mNote: you may need to restart the kernel using dbutils.library.restartPython() to use updated packages.\u001B[0m\n"
     ]
    }
   ],
   "source": [
    "pip install vaderSentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8268ef70-da28-4249-8d33-5b08a2716f78",
     "showTitle": false,
     "title": ""
    },
    "id": "xmcCH4XLrqtd"
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import DoubleType\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "def calculate_sentiment(text):\n",
    "    sid = SentimentIntensityAnalyzer()\n",
    "    return sid.polarity_scores(text)['compound']\n",
    "\n",
    "# Register the function as a UDF (User Defined Function)\n",
    "sentiment_udf = udf(calculate_sentiment, DoubleType())\n",
    "\n",
    "# Apply the UDF to create a new column with sentiment scores\n",
    "filtered_df = filtered_df.withColumn(\"sentiment_score\", sentiment_udf(filtered_df[\"tweet\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f28518dc-1cef-473a-9c6c-c97b4a431cb0",
     "showTitle": false,
     "title": ""
    },
    "id": "nNpvLH5trqtd"
   },
   "outputs": [],
   "source": [
    "def score_to_sentiment_label(score):\n",
    "    if score > 0:\n",
    "        return \"positive\"\n",
    "    else:\n",
    "        return \"negative\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "50d94c61-9374-4a62-b179-93af69c3e633",
     "showTitle": false,
     "title": ""
    },
    "id": "zXHJ0uZdTyFz"
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StringType\n",
    "\n",
    "# Register the function as a UDF (User Defined Function)\n",
    "sentiment_label_udf = udf(score_to_sentiment_label, StringType())\n",
    "\n",
    "# Apply the UDF to create a new column with sentiment labels\n",
    "filtered_df = filtered_df.withColumn(\"sentiment_label\", sentiment_label_udf(filtered_df[\"sentiment_score\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "48aef3ff-370d-4aeb-bd9c-e0002ac29fda",
     "showTitle": false,
     "title": ""
    },
    "id": "4YULp80mV-Io"
   },
   "outputs": [],
   "source": [
    "filtered_df = filtered_df.drop('sentiment_score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c97f38c3-092c-445f-90bd-9676aa8f63df",
     "showTitle": false,
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jvUmnzLCVHpy",
    "outputId": "93a67a9d-d68f-402d-f6dd-23f2f7dcf36c"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------+---------------+\n|               tweet|hashtag|sentiment_label|\n+--------------------+-------+---------------+\n|#Elecciones2020 |...|  Trump|       negative|\n|#Trump: As a stud...|  Trump|       positive|\n|You get a tie! An...|  Trump|       negative|\n|@CLady62 Her 15 m...|  Trump|       negative|\n|@DeeviousDenise @...|  Trump|       negative|\n+--------------------+-------+---------------+\nonly showing top 5 rows\n\n"
     ]
    }
   ],
   "source": [
    "filtered_df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "862a6693-c3d5-445a-9b78-a9ebbd7954ea",
     "showTitle": false,
     "title": ""
    },
    "id": "0tNKykPdWZTR"
   },
   "source": [
    "### TEXT CLEANING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b4912b66-39ff-495e-9456-0328409862b4",
     "showTitle": false,
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ckKXGUuSN2b_",
    "outputId": "819ad761-c8af-4c94-a9a3-cca822d23220"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[43mNote: you may need to restart the kernel using dbutils.library.restartPython() to use updated packages.\u001B[0m\nCollecting emoji\n  Downloading emoji-2.11.1-py2.py3-none-any.whl (433 kB)\n     ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 433.8/433.8 kB 10.5 MB/s eta 0:00:00\nInstalling collected packages: emoji\nSuccessfully installed emoji-2.11.1\n\u001B[43mNote: you may need to restart the kernel using dbutils.library.restartPython() to use updated packages.\u001B[0m\n"
     ]
    }
   ],
   "source": [
    "pip install emoji"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "977bc87c-21d2-4e4e-861a-074cb5717c95",
     "showTitle": false,
     "title": ""
    },
    "id": "BjPoMdL7WhDx"
   },
   "source": [
    "### 1. Removing Hashtags, usernames and urls from Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cd87c865-bbee-4b38-9246-169d948fdb41",
     "showTitle": false,
     "title": ""
    },
    "id": "a8qc_-idN2b_"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import emoji\n",
    "\n",
    "def get_emoji_regexp():\n",
    "    # Sort emoji by length to make sure multi-character emojis are matched first\n",
    "    emojis = sorted(emoji.EMOJI_DATA, key=len, reverse=True)\n",
    "    pattern = '(' + '|'.join(re.escape(u) for u in emojis) + ')'\n",
    "    return re.compile(pattern)\n",
    "\n",
    "exp = get_emoji_regexp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cd557190-185b-4922-b5fe-9b4d9d9920fe",
     "showTitle": false,
     "title": ""
    },
    "id": "hSG2Bh0QN2b_"
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import ArrayType, StringType\n",
    "\n",
    "# Define a function to remove URLs, emojis, and special characters\n",
    "def clean_text(text):\n",
    "    # Remove URLs\n",
    "    text = re.sub(r\"http\\S+|www.\\S+\", \"\", text)\n",
    "    # Remove emojis\n",
    "    text = re.sub(get_emoji_regexp(), \"\", text)\n",
    "    # Remove special characters\n",
    "    text = re.sub(r\"[^a-zA-Z0-9\\s]\", \"\", text)\n",
    "    return text\n",
    "\n",
    "# Define a UDF for cleaning text\n",
    "clean_text_udf = udf(clean_text, StringType())\n",
    "\n",
    "# Apply cleaning to the \"tweet\" column\n",
    "processed_data = filtered_df.withColumn(\"tweet_cleaned\", clean_text_udf(\"tweet\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8a46922c-ffb7-4f91-9fd7-c9a73ab4af71",
     "showTitle": false,
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Qdc_OyjYN2b_",
    "outputId": "37a6c67f-3fb2-4ba0-fa2b-be81c3d8b11a"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------+---------------+--------------------+\n|               tweet|hashtag|sentiment_label|       tweet_cleaned|\n+--------------------+-------+---------------+--------------------+\n|#Elecciones2020 |...|  Trump|       negative|Elecciones2020  E...|\n|#Trump: As a stud...|  Trump|       positive|Trump As a studen...|\n|You get a tie! An...|  Trump|       negative|You get a tie And...|\n|@CLady62 Her 15 m...|  Trump|       negative|CLady62 Her 15 mi...|\n|@DeeviousDenise @...|  Trump|       negative|DeeviousDenise re...|\n+--------------------+-------+---------------+--------------------+\nonly showing top 5 rows\n\n"
     ]
    }
   ],
   "source": [
    "processed_data.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4ec39285-85d6-4576-b32c-217aae167d26",
     "showTitle": false,
     "title": ""
    },
    "id": "Z8cJJ1XmXl0n"
   },
   "source": [
    "### 2. TOKENIZATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0ff7e773-d003-4fe0-956b-ed048b960379",
     "showTitle": false,
     "title": ""
    },
    "id": "3h4cGpMDrqte"
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import RegexTokenizer, StopWordsRemover, HashingTF\n",
    "\n",
    "regexTokenizer = RegexTokenizer(inputCol=\"tweet_cleaned\", outputCol=\"tokenized\", pattern=\"\\\\W\")\n",
    "tokenized = regexTokenizer.transform(processed_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f11ad042-8c8a-4828-be34-715fc0858fee",
     "showTitle": false,
     "title": ""
    },
    "id": "CnxwzaCmrqtf"
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import StopWordsRemover\n",
    "\n",
    "\n",
    "remover = StopWordsRemover(inputCol=\"tokenized\", outputCol=\"cleaned\")\n",
    "sw_removed = remover.transform(tokenized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "53f3e0e5-b2ee-48cb-8d2f-fc215e8f39a0",
     "showTitle": false,
     "title": ""
    },
    "id": "4OJXYO8crqtf"
   },
   "outputs": [],
   "source": [
    "hashTF = HashingTF(inputCol=\"cleaned\", outputCol=\"features\")\n",
    "result_df = hashTF.transform(sw_removed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3ced649e-0d5e-47a3-892c-4186e527266f",
     "showTitle": false,
     "title": ""
    },
    "id": "wj5T1tcsrqtf"
   },
   "outputs": [],
   "source": [
    "columns_to_drop = ['tokenized', 'tweet', 'cleaned']\n",
    "result_df = result_df.drop(*columns_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "44f71e7e-98ea-4023-8c9f-41e875eee4f0",
     "showTitle": false,
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mTrs0jE9rqtf",
    "outputId": "a606ef1a-69c0-4222-d291-f7e199ca10dd"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n|hashtag|sentiment_label|tweet_cleaned                                                                                                                                                                                                                                                                                 |features                                                                                                                                                                                                                                                                                                  |\n+-------+---------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n|Trump  |negative       |Elecciones2020  En Florida JoeBiden dice que DonaldTrump solo se preocupa por l mismo El demcrata fue anfitrin de encuentros de electores en PembrokePines y Miramar Clic AQU \\n\\n\\n\\nElSolLatino yobrilloconelsol                                                                            |(262144,[1303,30445,32297,43265,45835,46148,61392,72217,77899,92424,106834,112473,120751,124004,129701,131408,133494,142792,164359,168015,181864,183666,194559,201255,220451,252150,252367],[1.0,1.0,2.0,2.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])|\n|Trump  |positive       |Trump As a student I used to hear for years for ten years I heard China In 2019 And we have 15 and they dont know how many we have and I asked them how many do we have and they said sir we dont know But we have millions Like 300 million\\n\\nUm What                                       |(262144,[41129,55307,66273,76106,82288,87273,111370,120768,131217,136198,140931,153917,161061,168976,205538,208258,214720,230810,238047,245044,249283],[1.0,1.0,1.0,2.0,1.0,2.0,1.0,1.0,1.0,1.0,2.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,2.0,1.0])                                                             |\n|Trump  |negative       |You get a tie And you get a tie Trump s rally Iowa                                                                                                                                                                                                                                            |(262144,[46479,120768,229705,231821,252722],[2.0,1.0,1.0,1.0,2.0])                                                                                                                                                                                                                                        |\n|Trump  |negative       |CLady62 Her 15 minutes were over long time ago Omarosa never represented the black community TheReidOut \\n\\nShe cried to Trump begging for a job                                                                                                                                              |(262144,[12716,34366,36166,51832,66429,84145,99197,113673,120768,121517,129757,136198,146982,154828,187519,206312],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])                                                                                                                     |\n|Trump  |negative       |DeeviousDenise realDonaldTrump nypost There wont be many of them  Unless you all have been voting more than once again  But God prevails  BO was the most corrupt President ever  Dark to light  Your lies are all coming through  They wouldnt last forever Trump                            |(262144,[5381,6801,12409,57915,109208,120768,137777,153178,154643,166714,194250,203802,205069,207834,228780,228929,229305,235273,241498,245044,247989],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])                                                             |\n|Trump  |positive       |One of the single most effective remedies to eradicate another round of Trump Plague in our WhiteHouse                                                                                                                                                                                        |(262144,[1604,21823,58268,78833,83139,120768,134353,190003,251860,253382],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])                                                                                                                                                                                      |\n|Trump  |negative       |In 2020 NYPost is being censorship CENSORED by Twitter to manipulate a US election in favor of JoeBiden and against Trump\\n\\nbut CCP from China or porn on Twitter \\n\\nThats always been fine for jack vijaya dickc KatieS\\n\\nmarciadorsey is jack sick                                       |(262144,[1004,1512,2406,10345,27286,33579,37834,58870,79779,87896,109156,120768,154435,163885,164055,182577,194559,217316,219529,228929,230810,245951,261677],[1.0,2.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,2.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])                                              |\n|Trump  |positive       |Trump PresidentTrump Trump2020LandslideVictory Trump2020 MAGA KAG 4MoreYears America AmericaFirst AllLivesMatter Winning Vote VoteInPerson VoteTrump VotePresidentTrump                                                                                                                       |(262144,[22772,36149,49918,120768,136723,143603,163576,187873,219874,221520,230876,231338,258327,261333,261687],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])                                                                                                                            |\n|Trump  |negative       |cnnbrk Trump owes RicardoAguirre 730000 to pay for the mass murder of his family TrumpLiedPeopleDied FauciFan                                                                                                                                                                                 |(262144,[51621,86807,92607,118384,120768,141368,199882,221017,232888,239713,252585],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])                                                                                                                                                                        |\n|Trump  |positive       |Democrats have spent more tax payer paid time amp money on chasing amp attacking TRUMP not doing their jobs serving the public as elected USA NO GOOD REASONS NOT TO ECONOMICALLY BAIL PEOPLE OUT amp PROTECT THEM TOO AS YOU TOOK OATH TOO USA                                               |(262144,[5022,7019,68080,68723,80649,83895,91277,113432,117041,120768,121517,134711,149437,154459,174506,175778,176028,184523,185559,193809,235174,239982,240407,249943],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,2.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,3.0,1.0,1.0])                               |\n|Trump  |positive       |Trump Nobody likes to tell you this but some of the farmers were doing better the way I was doing it than they were by working their asses off\\n\\nAnd that check Its totally in the mail right Don                                                                                            |(262144,[51471,65908,71450,85530,120768,191530,198131,200622,203005,203389,229166,229507,235375],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])                                                                                                                                                   |\n|Trump  |negative       |RudyGiuliani Twitter PressSec You right RudyGiuliani Censorship should be Condemned \\nCc Trump and the GOP\\n\\nNot the American way\\n\\nNow lets redo Trumps Impeachment this time without the CENSORSHIP\\nAmericaFirst BidenCares DonaldTrump BidenWillCrushCovid BidenHarris2020ToSaveAmerica |(262144,[1512,2482,22772,51471,58870,70359,72799,120768,121517,127866,138836,158433,168737,169008,183339,183666,216662,223102,229166,238931,239127,258969],[1.0,1.0,1.0,1.0,2.0,1.0,1.0,1.0,1.0,1.0,1.0,2.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])                                                     |\n|Trump  |negative       |Comments on this Do Democrats Understand how Ruthless China is  China HunterBiden JoeBiden BidenHarris BidenHarris2020 TrumpPence2020 Trump realDonaldTrump WTO coronavirus trade                                                                                                             |(262144,[60862,91277,102211,120768,137777,158425,178221,180003,194559,194695,220547,220806,225159,230810,245605],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,2.0,1.0])                                                                                                                           |\n|Trump  |negative       |karatblood KazePlaysJC Grab realDonaldTrump by the balls amp chuck the bastard out the door onto PennsylvaniaAvenue amp form a line amp everybody gets to kick DonaldTrump in the nuts Please note 1 kick per person only BidenHarrisToSaveAmerica VoteBlueToSaveOurDemocracy                 |(262144,[12650,43157,44876,59426,80431,85285,86576,91028,92651,103430,110078,137777,138021,152049,152823,159464,166368,178518,183666,198358,211294,227594,233903,239982,260465],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,2.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,3.0,1.0])                    |\n|Trump  |negative       |Ice Cube is teaming up to work with President Trump in developing The Platinum Plan 2020election AfricanAmericans BlackAmerican DiamondandSilk DonaldTrump featuredonWJLive politics race TWJReports USnews                                                                                   |(262144,[454,34343,48489,62916,66034,84809,86856,103473,110647,120768,130733,141063,153178,183666,188746,221900,227686,232427,249855],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])                                                                                      |\n|Trump  |negative       |BlacksForTrump \\nBlackVoicesForTrump \\nBidenIsARacist \\nBlackFathersMatter \\nBlackVotersMatter \\nVote GOP down ticket amp give Trump somebody to work with \\nDemocratsAreDestroyingAmerica                                                                                                    |(262144,[34343,38552,49918,53454,59676,107367,120768,146888,152065,161530,182817,215474,239127,239982],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])                                                                                                                                         |\n|Trump  |negative       |ChrisDJackson New respect here for Scaramucci \\n\\nThe vile hateful ugliness of Trumps LawAndOrder America                                                                                                                                                                                     |(262144,[19282,40542,82079,89833,103770,156514,165112,183296,230876,238931],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])                                                                                                                                                                                    |\n|Trump  |negative       |Who does trump owe 420 million dollars to What are the terms Who is DonaldTrump beholden to WE DEMAND TO KNOW\\nTrumpIsANationalSecurityRisk \\nFollowTheMoney \\nTrumpTaxCheat \\nTrumpTaxFraud                                                                                                  |(262144,[4978,55307,62829,89121,120768,140931,164184,172482,180504,183375,183666,188041,209741,215054],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])                                                                                                                                         |\n|Trump  |negative       |JimJordan DevinNunes MattGaetz JohnCornyn BillBarr DonaldTrump amp the rest who railed about it should be indicted amp go to jail for perpetuating a fraud against the American people over the perfectly legal unmasking of General Flynn\\nThey make me sick\\n\\nLockThemUp                   |(262144,[3924,6590,28165,41351,46402,71882,89717,91767,94638,102119,102388,113241,114429,115776,138836,148675,152657,164342,183666,185559,225308,235184,239982,261677],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,2.0,1.0])                                 |\n|Trump  |negative       |TheWeek Trump in Penn I saved suburbia I got rid of a regulation that was a disaster and it was really unfair and its gotten a lot worse under Obama and Biden You damn well better vote for me Pennsylvania you better vote But he never did identify the regulation                         |(262144,[8522,40957,46197,49918,51011,71175,98142,113312,113673,114179,120768,153946,158845,159901,186925,187359,216372,225898,229264,235375,242239,244728,245599],[1.0,1.0,1.0,2.0,1.0,2.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,2.0,1.0,1.0,1.0])                                         |\n+-------+---------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\nonly showing top 20 rows\n\n"
     ]
    }
   ],
   "source": [
    "result_df.show(truncate = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ac45d3a5-196f-4f3c-bdee-fb12433c6bd5",
     "showTitle": false,
     "title": ""
    },
    "id": "TuDwgFAjZA3O"
   },
   "source": [
    "### CREATING A CUSTOM FUNCTION TO ENCODE HASHTAG COLUMN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3bf27bec-4059-4bf5-aa31-c1edda6c86b9",
     "showTitle": false,
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FxTII7gUY4wV",
    "outputId": "8b5195ae-6cd5-4289-e46e-c1974e8f341c"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------------+--------------------+--------------------+---------------+\n|hashtag|sentiment_label|       tweet_cleaned|            features|hashtag_encoded|\n+-------+---------------+--------------------+--------------------+---------------+\n|  Trump|       negative|Elecciones2020  E...|(262144,[1303,304...|              1|\n|  Trump|       positive|Trump As a studen...|(262144,[41129,55...|              1|\n|  Trump|       negative|You get a tie And...|(262144,[46479,12...|              1|\n|  Trump|       negative|CLady62 Her 15 mi...|(262144,[12716,34...|              1|\n|  Trump|       negative|DeeviousDenise re...|(262144,[5381,680...|              1|\n|  Trump|       positive|One of the single...|(262144,[1604,218...|              1|\n|  Trump|       negative|In 2020 NYPost is...|(262144,[1004,151...|              1|\n|  Trump|       positive|Trump PresidentTr...|(262144,[22772,36...|              1|\n|  Trump|       negative|cnnbrk Trump owes...|(262144,[51621,86...|              1|\n|  Trump|       positive|Democrats have sp...|(262144,[5022,701...|              1|\n|  Trump|       positive|Trump Nobody like...|(262144,[51471,65...|              1|\n|  Trump|       negative|RudyGiuliani Twit...|(262144,[1512,248...|              1|\n|  Trump|       negative|Comments on this ...|(262144,[60862,91...|              1|\n|  Trump|       negative|karatblood KazePl...|(262144,[12650,43...|              1|\n|  Trump|       negative|Ice Cube is teami...|(262144,[454,3434...|              1|\n|  Trump|       negative|BlacksForTrump \\n...|(262144,[34343,38...|              1|\n|  Trump|       negative|ChrisDJackson New...|(262144,[19282,40...|              1|\n|  Trump|       negative|Who does trump ow...|(262144,[4978,553...|              1|\n|  Trump|       negative|JimJordan DevinNu...|(262144,[3924,659...|              1|\n|  Trump|       negative|TheWeek Trump in ...|(262144,[8522,409...|              1|\n+-------+---------------+--------------------+--------------------+---------------+\nonly showing top 20 rows\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import when\n",
    "\n",
    "# Define the conditions for encoding\n",
    "trump_condition = (col(\"hashtag\") == \"Trump\")\n",
    "biden_condition = (col(\"hashtag\") == \"Biden\")\n",
    "\n",
    "# Define the values to assign for each condition\n",
    "trump_value = 1  # You can choose any numeric value\n",
    "biden_value = 2  #\n",
    "\n",
    "# Apply the conditions and assign values using when function\n",
    "result_df = result_df.withColumn(\"hashtag_encoded\",\n",
    "                                    when(trump_condition, trump_value)\n",
    "                                    .when(biden_condition, biden_value)\n",
    "                                    .otherwise(0))  # Assign 0 for other cases\n",
    "\n",
    "# Show the DataFrame with the new encoded column\n",
    "result_df.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9119f99d-ce9b-40a6-b268-be87bb1c34ec",
     "showTitle": false,
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HBAhbfQurqtf",
    "outputId": "fe8fb390-225b-4a9c-af7a-a0d107b0e513"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------------+--------------------+--------------------+---------------+-----------------+\n|hashtag|sentiment_label|       tweet_cleaned|            features|hashtag_encoded|sentiment_encoded|\n+-------+---------------+--------------------+--------------------+---------------+-----------------+\n|  Trump|       negative|Elecciones2020  E...|(262144,[1303,304...|              1|                0|\n|  Trump|       positive|Trump As a studen...|(262144,[41129,55...|              1|                1|\n|  Trump|       negative|You get a tie And...|(262144,[46479,12...|              1|                0|\n|  Trump|       negative|CLady62 Her 15 mi...|(262144,[12716,34...|              1|                0|\n|  Trump|       negative|DeeviousDenise re...|(262144,[5381,680...|              1|                0|\n+-------+---------------+--------------------+--------------------+---------------+-----------------+\nonly showing top 5 rows\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import udf, col\n",
    "from pyspark.sql.types import IntegerType\n",
    "from pyspark.sql.functions import when\n",
    "\n",
    "# Defining the conditions for encoding\n",
    "negative_condition = (col(\"sentiment_label\") == \"negative\")\n",
    "positive_condition = (col(\"sentiment_label\") == \"positive\")\n",
    "\n",
    "# Applying the conditions and assign values using when function\n",
    "result_df = result_df.withColumn(\"sentiment_encoded\",\n",
    "                                    when(negative_condition, 0)\n",
    "                                    .when(positive_condition,1))\n",
    "\n",
    "# Shoing the DataFrame with the new encoded column\n",
    "result_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "60c36bfc-d9ee-4d99-8d86-46a8567942a1",
     "showTitle": false,
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oDv6ofVSpfd1",
    "outputId": "05fe34b9-d6ee-4417-c18a-29793ba1a02d"
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "# Filter the data into separate DataFrames based on the hashtag\n",
    "trump_data = result_df.filter(col(\"hashtag\") == \"Trump\")\n",
    "biden_data = result_df.filter(col(\"hashtag\") == \"Biden\")\n",
    "\n",
    "# Sample 25,000 rows from each DataFrame\n",
    "sampled_trump_data = trump_data.sample(False, 25000 / trump_data.count(), seed=42)\n",
    "sampled_biden_data = biden_data.sample(False, 25000 / biden_data.count(), seed=42)\n",
    "\n",
    "# Union the sampled subsets together to create the final DataFrame\n",
    "final_subset_data = sampled_trump_data.union(sampled_biden_data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "28fb3d6a-a1d5-4899-a3f3-7dc28c507598",
     "showTitle": false,
     "title": ""
    },
    "id": "8_mJJJDabT-r"
   },
   "source": [
    "### BUILDING THE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6f961121-af8d-4cb8-a313-29549faf7116",
     "showTitle": false,
     "title": ""
    },
    "id": "pDidhkuNN2cB"
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "featureassembler = VectorAssembler(inputCols= [\"features\",\"hashtag_encoded\"], outputCol= \"Independent Features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "eb68e067-cff3-4d57-b77c-3342c8d499cf",
     "showTitle": false,
     "title": ""
    },
    "id": "NFUsIU8CctfU"
   },
   "outputs": [],
   "source": [
    "output = featureassembler.transform(final_subset_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d7e54373-2c52-45a6-869d-109432aa982f",
     "showTitle": false,
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WkcyFoZ0c1mN",
    "outputId": "239ae152-7979-4e19-920d-509a2900ec28"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------------+--------------------+--------------------+---------------+-----------------+--------------------+\n|hashtag|sentiment_label|       tweet_cleaned|            features|hashtag_encoded|sentiment_encoded|Independent Features|\n+-------+---------------+--------------------+--------------------+---------------+-----------------+--------------------+\n|  Trump|       positive|Trump PresidentTr...|(262144,[22772,36...|              1|                1|(262145,[22772,36...|\n|  Trump|       negative|ChrisDJackson New...|(262144,[19282,40...|              1|                0|(262145,[19282,40...|\n|  Trump|       negative|JimJordan DevinNu...|(262144,[3924,659...|              1|                0|(262145,[3924,659...|\n|  Trump|       negative|realDonaldTrump U...|(262144,[12072,18...|              1|                0|(262145,[12072,18...|\n|  Trump|       positive|Trump has been ba...|(262144,[93197,95...|              1|                1|(262145,[93197,95...|\n+-------+---------------+--------------------+--------------------+---------------+-----------------+--------------------+\nonly showing top 5 rows\n\n"
     ]
    }
   ],
   "source": [
    "output.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "69d25cac-0f05-4700-8ed0-0bfb902d3174",
     "showTitle": false,
     "title": ""
    },
    "id": "vajgVCvnc_Hn"
   },
   "outputs": [],
   "source": [
    "finalized_data = output.select(\"Independent Features\",\"sentiment_encoded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0e6fbd8e-3e41-404c-8f29-230f90a89843",
     "showTitle": false,
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UIVMesp3dD4o",
    "outputId": "e7ad719c-cc5f-4e3d-ceab-5ac6010f9fde"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----------------+\n|Independent Features|sentiment_encoded|\n+--------------------+-----------------+\n|(262145,[22772,36...|                1|\n|(262145,[19282,40...|                0|\n|(262145,[3924,659...|                0|\n|(262145,[12072,18...|                0|\n|(262145,[93197,95...|                1|\n+--------------------+-----------------+\nonly showing top 5 rows\n\n"
     ]
    }
   ],
   "source": [
    "finalized_data.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "91654192-2902-41b2-9a49-074a7c1e3338",
     "showTitle": false,
     "title": ""
    },
    "id": "euS2Q4mvdD2c"
   },
   "outputs": [],
   "source": [
    "# train test split\n",
    "train_data, test_data = finalized_data.randomSplit([0.75,0.25])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "76ea4f8a-d493-4e80-bd78-9076b1fffbd5",
     "showTitle": false,
     "title": ""
    },
    "id": "LfHPYMiPqB-7"
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "\n",
    "# Assuming you have already assembled the features and prepared the data\n",
    "\n",
    "# Define the logistic regression model\n",
    "log_reg = LogisticRegression(featuresCol=\"Independent Features\", labelCol=\"sentiment_encoded\",maxIter=10,regParam=0.01)\n",
    "\n",
    "# Fit the logistic regression model\n",
    "model = log_reg.fit(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "29bcbc9e-abd6-4ffb-8dac-e1450452568c",
     "showTitle": false,
     "title": ""
    },
    "id": "OBf0Px0OqSZn"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy: 0.8534435493071367\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on the test data\n",
    "predictions = model.transform(test_data)\n",
    "\n",
    "# Evaluate the model\n",
    "evaluator = BinaryClassificationEvaluator(labelCol=\"sentiment_encoded\")\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "\n",
    "# Print the accuracy\n",
    "print(\"Logistic Regression Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "29be2521-f533-4b86-815a-cf89eaac7e53",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    " \n",
    "# Assuming you have already assembled the features and prepared the data\n",
    " \n",
    "# Define the Random Forest classifier\n",
    "rf = RandomForestClassifier(featuresCol=\"Independent Features\", labelCol=\"sentiment_encoded\")\n",
    " \n",
    "# Fit the Random Forest model\n",
    "rf_model = rf.fit(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a02b183e-9606-461f-979d-21628360c4bf",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Accuracy: 0.612232472736824\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on the test data\n",
    "rf_predictions = rf_model.transform(test_data)\n",
    " \n",
    "# Evaluate the model using BinaryClassificationEvaluator\n",
    "rf_evaluator = BinaryClassificationEvaluator(labelCol=\"sentiment_encoded\")\n",
    " \n",
    "# Area Under the ROC Curve (AUC) is the default metric for BinaryClassificationEvaluator\n",
    "rf_accuracy = rf_evaluator.evaluate(rf_predictions)\n",
    " \n",
    "# Print the accuracy\n",
    "print(\"Random Forest Accuracy:\", rf_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bd46dc0f-75a2-49bd-86bb-2fc85a15b9a0",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC Accuracy: 0.8748350682149089\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import LinearSVC\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    " \n",
    "# Define the Linear SVC classifier\n",
    "svc = LinearSVC(featuresCol=\"Independent Features\", labelCol=\"sentiment_encoded\")\n",
    " \n",
    "# Fit the SVC model\n",
    "svc_model = svc.fit(train_data)\n",
    "svc_predictions = svc_model.transform(test_data)\n",
    " \n",
    "# Evaluate the model using BinaryClassificationEvaluator\n",
    "svc_evaluator = BinaryClassificationEvaluator(labelCol=\"sentiment_encoded\")\n",
    " \n",
    "# Area Under the ROC Curve (AUC) is the default metric for BinaryClassificationEvaluator\n",
    "svc_accuracy = svc_evaluator.evaluate(svc_predictions)\n",
    " \n",
    "# Print the accuracy\n",
    "print(\"SVC Accuracy:\", svc_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0defc0a9-9ba0-442d-ae09-e9d45c1ab9a2",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### RESULTS:\n",
    "1. Logistic Regression : 85%\n",
    "2. Random Forest Classifier : 61%\n",
    "3. Support Vector Machine Classifier : 87%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "bba66807-c793-4d13-97d9-ce105c4790e8",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### Support Vector Classifier proved to be the most efficient model for Twitter Sentiment Analysis."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "2 - Data_Preprocessing and Model Building",
   "widgets": {}
  },
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
